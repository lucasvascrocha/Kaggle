{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "class Feat_select:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def rank(self, df):\n",
    "            \"\"\"\n",
    "            Entrada dos 3 data frames de empresas conhecidas\n",
    "            Retorna uma lista com combinações de features selecionadas por Random Forest Rank\n",
    "            necessita da entrada de 3 df distintos que representem algum grupo pré estabelecido\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            X = df.drop(['Survived'], axis=1)\n",
    "            y = df['Survived']\n",
    "            # estimators\n",
    "            rf = RandomForestClassifier()\n",
    "            rf = rf.fit(X, y)\n",
    "            rfe = RFE(rf, n_features_to_select=1, verbose=2)\n",
    "            rfe = rfe.fit(X, y)\n",
    "            rank = pd.DataFrame({'features': X.columns})\n",
    "            rank['RF rank'] = rfe.ranking_\n",
    "\n",
    "            rfr = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)\n",
    "            rfr.fit(X, y)\n",
    "            rank['RFR'] = (rfr.feature_importances_ * 100)\n",
    "\n",
    "            linreg = LinearRegression(normalize=True)\n",
    "            linreg.fit(X, y)\n",
    "            rank['linreg'] = (linreg.coef_.round(3) * 10)\n",
    "\n",
    "            model = LogisticRegression(solver='liblinear')\n",
    "            rfe = RFE(model, 3)\n",
    "            rfe = rfe.fit(X, y)\n",
    "            rank['logreg'] = rfe.ranking_\n",
    "\n",
    "            etc = ExtraTreesClassifier()\n",
    "            etc.fit(X, y)\n",
    "            rank['etc'] = (etc.feature_importances_.round(3) * 100)\n",
    "\n",
    "            test = SelectKBest(score_func=f_classif, k=4)\n",
    "            fit = test.fit(X, y)\n",
    "            set_printoptions(precision=3)\n",
    "            rank['f_score'] = fit.scores_\n",
    "            print(rank.sort_values('RF rank', ascending=True))\n",
    "\n",
    "            # opções de listas de features selecionadas para cada estimador\n",
    "            lista_comb_feat_RFR = []\n",
    "            lista_comb_feat_RFrank = []\n",
    "            lista_comb_feat_linreg = []\n",
    "            lista_comb_feat_logreg = []\n",
    "            lista_comb_feat_etc = []\n",
    "            lista_comb_feat_f_score = []\n",
    "            for x in range(2, 11):\n",
    "                lista_comb_feat_RFR.append(rank.sort_values('RFR', ascending=False).head(x)['features'].tolist())\n",
    "                lista_comb_feat_RFrank.append(rank.sort_values('RF rank', ascending=True).head(x)['features'].tolist())\n",
    "                lista_comb_feat_linreg.append(rank.sort_values('linreg', ascending=False).head(x)['features'].tolist())\n",
    "                lista_comb_feat_logreg.append(rank.sort_values('logreg', ascending=True).head(x)['features'].tolist())\n",
    "                lista_comb_feat_etc.append(rank.sort_values('etc', ascending=False).head(x)['features'].tolist())\n",
    "                lista_comb_feat_f_score.append(rank.sort_values('f_score', ascending=False).head(x)['features'].tolist())\n",
    "\n",
    "            return lista_comb_feat_RFrank\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clifford, Mr. George Quincy</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110465</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>A14</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Rugg, Miss. Emily</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 31026</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hawksford, Mr. Walter James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16988</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>D45</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Thayer, Mr. John Borland</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17421</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>C68</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                         Name     Sex   Age  \\\n",
       "0          476         0       1  Clifford, Mr. George Quincy    male   NaN   \n",
       "1           57         1       2            Rugg, Miss. Emily  female  21.0   \n",
       "2          259         1       1             Ward, Miss. Anna  female  35.0   \n",
       "3          741         1       1  Hawksford, Mr. Walter James    male   NaN   \n",
       "4          699         0       1     Thayer, Mr. John Borland    male  49.0   \n",
       "\n",
       "   SibSp  Parch      Ticket      Fare Cabin Embarked  \n",
       "0      0      0      110465   52.0000   A14        S  \n",
       "1      0      0  C.A. 31026   10.5000   NaN        S  \n",
       "2      0      0    PC 17755  512.3292   NaN        C  \n",
       "3      0      0       16988   30.0000   D45        S  \n",
       "4      1      1       17421  110.8833   C68        C  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "      <th>tipos</th>\n",
       "      <th>NA #</th>\n",
       "      <th>NA %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>Survived</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>Sex</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>Age</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>Parch</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>Fare</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nomes    tipos  NA #  NA %\n",
       "Survived  Survived    int64     0   0.0\n",
       "Pclass      Pclass    int64     0   0.0\n",
       "Sex            Sex   object     0   0.0\n",
       "Age            Age  float64     0   0.0\n",
       "SibSp        SibSp    int64     0   0.0\n",
       "Parch        Parch    int64     0   0.0\n",
       "Fare          Fare  float64     0   0.0\n",
       "Embarked  Embarked   object     0   0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploracao = pd.DataFrame({'nomes': df.columns, 'tipos': df.dtypes,\n",
    "                                   'NA #': df.isna().sum(), 'NA %': (df.isna().sum() / df.shape[0]) * 100})\n",
    "exploracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>452.372392</td>\n",
       "      <td>0.394864</td>\n",
       "      <td>2.295345</td>\n",
       "      <td>29.344575</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>0.398074</td>\n",
       "      <td>33.810232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>251.236932</td>\n",
       "      <td>0.489214</td>\n",
       "      <td>0.846457</td>\n",
       "      <td>13.049252</td>\n",
       "      <td>1.085521</td>\n",
       "      <td>0.826877</td>\n",
       "      <td>51.205014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>242.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>448.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>665.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   623.000000  623.000000  623.000000  623.000000  623.000000   \n",
       "mean    452.372392    0.394864    2.295345   29.344575    0.536116   \n",
       "std     251.236932    0.489214    0.846457   13.049252    1.085521   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     242.500000    0.000000    1.000000   22.000000    0.000000   \n",
       "50%     448.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     665.000000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  623.000000  623.000000  \n",
       "mean     0.398074   33.810232  \n",
       "std      0.826877   51.205014  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.925000  \n",
       "50%      0.000000   14.500000  \n",
       "75%      0.000000   33.760400  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Cabin', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
       "0         0       1    male  28.0      0      0   52.0000        S\n",
       "1         1       2  female  21.0      0      0   10.5000        S\n",
       "2         1       1  female  35.0      0      0  512.3292        C\n",
       "3         1       1    male  28.0      0      0   30.0000        S\n",
       "4         0       1    male  49.0      1      1  110.8833        C"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dummies_object = ['Sex','Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch      Fare  Sex_male  Embarked_Q  \\\n",
       "0         0       1  28.0      0      0   52.0000         1           0   \n",
       "1         1       2  21.0      0      0   10.5000         0           0   \n",
       "2         1       1  35.0      0      0  512.3292         0           0   \n",
       "3         1       1  28.0      0      0   30.0000         1           0   \n",
       "4         0       1  49.0      1      1  110.8833         1           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df[list_dummies_object], drop_first=True)\n",
    "df_dummy = pd.concat([df.drop(list_dummies_object, axis=1), dummies], axis=1)\n",
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50building tree 4 of 50\n",
      "\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50building tree 7 of 50\n",
      "\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50building tree 10 of 50\n",
      "\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50building tree 14 of 50\n",
      "\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50building tree 17 of 50\n",
      "\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50building tree 21 of 50\n",
      "\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50building tree 25 of 50\n",
      "\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50building tree 28 of 50\n",
      "\n",
      "building tree 29 of 50building tree 30 of 50\n",
      "\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50building tree 36 of 50\n",
      "\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50building tree 39 of 50\n",
      "building tree 40 of 50building tree 41 of 50\n",
      "\n",
      "\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50building tree 44 of 50building tree 45 of 50\n",
      "\n",
      "\n",
      "building tree 46 of 50building tree 47 of 50\n",
      "\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "     features  RF rank        RFR  linreg  logreg   etc     f_score\n",
      "4        Fare        1  25.152677    0.00       6  24.6   41.152272\n",
      "1         Age        2  24.263221   -0.06       4  22.5    1.602310\n",
      "5    Sex_male        3  30.601087   -5.11       1  28.7  254.210615\n",
      "0      Pclass        4  10.566206   -1.69       1  11.4   78.940077\n",
      "2       SibSp        5   3.688778   -0.46       1   4.3    0.486855\n",
      "3       Parch        6   2.746816   -0.13       5   5.5    5.505477\n",
      "7  Embarked_S        7   2.390468   -0.35       2   1.9    6.894873\n",
      "6  Embarked_Q        8   0.590747   -0.19       3   1.0    0.568519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Fare', 'Age'],\n",
       " ['Fare', 'Age', 'Sex_male'],\n",
       " ['Fare', 'Age', 'Sex_male', 'Pclass'],\n",
       " ['Fare', 'Age', 'Sex_male', 'Pclass', 'SibSp'],\n",
       " ['Fare', 'Age', 'Sex_male', 'Pclass', 'SibSp', 'Parch'],\n",
       " ['Fare', 'Age', 'Sex_male', 'Pclass', 'SibSp', 'Parch', 'Embarked_S'],\n",
       " ['Fare',\n",
       "  'Age',\n",
       "  'Sex_male',\n",
       "  'Pclass',\n",
       "  'SibSp',\n",
       "  'Parch',\n",
       "  'Embarked_S',\n",
       "  'Embarked_Q'],\n",
       " ['Fare',\n",
       "  'Age',\n",
       "  'Sex_male',\n",
       "  'Pclass',\n",
       "  'SibSp',\n",
       "  'Parch',\n",
       "  'Embarked_S',\n",
       "  'Embarked_Q'],\n",
       " ['Fare',\n",
       "  'Age',\n",
       "  'Sex_male',\n",
       "  'Pclass',\n",
       "  'SibSp',\n",
       "  'Parch',\n",
       "  'Embarked_S',\n",
       "  'Embarked_Q']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feat_select().rank(df_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy.drop('Survived',axis=1)\n",
    "y = df_dummy['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGR: 0.782642 (0.061594)\n",
      "RFC: 0.814823 (0.052100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETC: 0.803559 (0.043070)\n",
      "LDA: 0.784229 (0.054021)\n",
      "KNN: 0.693984 (0.065147)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.771429 (0.067183)\n",
      "NB: 0.760087 (0.055028)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/home/lucas/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.668228 (0.062768)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LOGR', LogisticRegression()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "models.append(('ETC', ExtraTreesClassifier()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = LinearRegression()\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>113.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass    Age  SibSp  Parch      Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "0       3  20.00      0      0    7.0500         1           0           1\n",
       "1       3  18.00      2      0   18.0000         0           0           1\n",
       "2       2   0.67      1      1   14.5000         1           0           1\n",
       "3       1  58.00      0      2  113.2750         1           0           0\n",
       "4       3  30.00      0      0    7.2292         1           0           0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(test[list_dummies_object], drop_first=True)\n",
    "test_dummy = pd.concat([test.drop(list_dummies_object, axis=1), dummies], axis=1)\n",
    "test_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.157,  0.581,  0.364,  0.353,  0.172,  0.157,  0.458,  0.191,\n",
       "        0.113,  0.768,  0.053,  0.06 ,  0.046,  0.723,  0.181,  0.108,\n",
       "        0.238,  0.746,  0.07 ,  0.111,  0.624,  0.265,  0.757,  0.017,\n",
       "        0.124,  0.668,  0.706,  0.387,  0.595,  0.139,  0.318,  0.646,\n",
       "        0.124,  0.153,  0.386,  0.248,  0.157,  0.594,  0.162,  0.69 ,\n",
       "        0.008,  0.71 ,  0.897, -0.069,  0.303,  0.376,  0.117,  0.593,\n",
       "        0.074,  0.113,  0.255,  0.113, -0.006,  0.601,  0.293,  0.342,\n",
       "        0.091,  0.118,  0.015,  0.592,  0.183,  0.146,  0.221,  0.705,\n",
       "        0.21 ,  0.388,  0.183,  0.998,  0.135,  0.033,  0.258,  0.549,\n",
       "       -0.069,  0.113,  0.133,  0.951,  0.174,  0.293,  0.112,  0.673,\n",
       "        1.044,  0.089,  0.189,  0.085,  0.149,  0.681,  0.387,  0.254,\n",
       "        0.291,  0.733,  0.647,  0.047,  1.073,  0.354,  0.146,  0.255,\n",
       "        0.24 ,  0.669,  1.015,  0.696,  0.282,  0.113, -0.279,  0.273,\n",
       "        0.153,  0.122,  0.048,  0.113,  0.291,  0.157,  0.656,  0.188,\n",
       "        0.073, -0.14 ,  0.364,  0.457,  0.074,  0.82 ,  0.135,  0.584,\n",
       "        0.392,  0.237, -0.279,  0.749,  0.953,  0.101,  0.118,  0.151,\n",
       "        0.276,  0.119,  0.113,  0.113,  0.793, -0.039,  0.989,  0.69 ,\n",
       "        0.992,  0.2  ,  0.706,  0.059,  0.055,  0.647,  0.707,  0.058,\n",
       "        0.679,  0.017,  0.425,  0.232,  0.285,  0.728,  0.392,  0.273,\n",
       "        0.091,  0.789,  0.238,  0.183,  0.685,  0.389,  0.217,  0.32 ,\n",
       "        1.004,  0.162,  0.157,  0.107,  0.859,  0.647,  0.259,  0.129,\n",
       "        0.124,  0.246,  0.492,  0.157,  0.647,  0.718,  0.793,  0.151,\n",
       "        0.936,  0.204,  0.172,  0.76 ,  0.347,  0.843,  0.365,  0.69 ,\n",
       "        0.113,  0.113,  0.817,  0.314,  0.763,  0.873,  0.079,  0.699,\n",
       "        0.382,  0.151,  0.075,  0.108,  0.113,  0.875,  0.713,  0.013,\n",
       "       -0.048,  0.371,  0.244,  0.113, -0.014,  0.216,  0.637,  0.1  ,\n",
       "        0.904,  0.113,  0.776,  0.824,  0.113,  0.246,  0.565,  0.163,\n",
       "        0.183,  0.061,  0.124,  0.275,  0.962,  0.14 ,  0.245,  0.052,\n",
       "        0.091,  0.265,  0.713,  0.151,  0.124,  0.146,  0.257,  0.216,\n",
       "        0.08 ,  0.183,  0.96 ,  0.135,  0.647,  0.168,  0.067,  0.343,\n",
       "        0.113,  0.119,  0.647,  0.043,  0.716,  0.472,  0.328,  0.227,\n",
       "        0.624,  0.151,  0.673,  0.216,  0.881,  0.124,  0.128,  1.016,\n",
       "        0.135,  0.624,  0.322,  0.151,  0.867,  1.058,  0.359,  0.124,\n",
       "        0.041,  0.76 ,  0.81 ,  0.821])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dummy = sc.transform(test_dummy)\n",
    "pred = cls.predict(test_dummy)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Survived'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>431.186567</td>\n",
       "      <td>0.336047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>270.945388</td>\n",
       "      <td>0.281881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.250000</td>\n",
       "      <td>0.112757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.234712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>677.000000</td>\n",
       "      <td>0.623703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>887.000000</td>\n",
       "      <td>0.997887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived\n",
       "count   268.000000  268.000000\n",
       "mean    431.186567    0.336047\n",
       "std     270.945388    0.281881\n",
       "min       4.000000    0.000000\n",
       "25%     177.250000    0.112757\n",
       "50%     439.000000    0.234712\n",
       "75%     677.000000    0.623703\n",
       "max     887.000000    0.997887"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "result[['Survived']] = result[['Survived']].clip(lower=0)\n",
    "\n",
    "\n",
    "\n",
    "for n in range (len(result['Survived'])):\n",
    "    if result['Survived'][n] > 1:\n",
    "        result['Survived'][n] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/home/lucas/PycharmProjects/git/Kaggle competitions/result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy.drop('Survived',axis=1).values\n",
    "y = df_dummy['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))  #neuron nets\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))  # output\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 434 samples, validate on 187 samples\n",
      "Epoch 1/400\n",
      "434/434 [==============================] - 1s 3ms/sample - loss: 0.4003 - val_loss: 0.3919\n",
      "Epoch 2/400\n",
      "434/434 [==============================] - 0s 81us/sample - loss: 0.3830 - val_loss: 0.3768\n",
      "Epoch 3/400\n",
      "434/434 [==============================] - 0s 56us/sample - loss: 0.3695 - val_loss: 0.3635\n",
      "Epoch 4/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.3561 - val_loss: 0.3509\n",
      "Epoch 5/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.3446 - val_loss: 0.3387\n",
      "Epoch 6/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.3326 - val_loss: 0.3277\n",
      "Epoch 7/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.3222 - val_loss: 0.3176\n",
      "Epoch 8/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.3124 - val_loss: 0.3083\n",
      "Epoch 9/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.3035 - val_loss: 0.2990\n",
      "Epoch 10/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.2938 - val_loss: 0.2902\n",
      "Epoch 11/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.2848 - val_loss: 0.2818\n",
      "Epoch 12/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.2772 - val_loss: 0.2744\n",
      "Epoch 13/400\n",
      "434/434 [==============================] - 0s 49us/sample - loss: 0.2708 - val_loss: 0.2686\n",
      "Epoch 14/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.2655 - val_loss: 0.2645\n",
      "Epoch 15/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.2613 - val_loss: 0.2615\n",
      "Epoch 16/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.2585 - val_loss: 0.2591\n",
      "Epoch 17/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.2558 - val_loss: 0.2568\n",
      "Epoch 18/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.2531 - val_loss: 0.2545\n",
      "Epoch 19/400\n",
      "434/434 [==============================] - 0s 54us/sample - loss: 0.2511 - val_loss: 0.2523\n",
      "Epoch 20/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.2487 - val_loss: 0.2502\n",
      "Epoch 21/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.2466 - val_loss: 0.2483\n",
      "Epoch 22/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.2445 - val_loss: 0.2462\n",
      "Epoch 23/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.2424 - val_loss: 0.2442\n",
      "Epoch 24/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.2403 - val_loss: 0.2423\n",
      "Epoch 25/400\n",
      "434/434 [==============================] - 0s 75us/sample - loss: 0.2382 - val_loss: 0.2405\n",
      "Epoch 26/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.2361 - val_loss: 0.2385\n",
      "Epoch 27/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.2342 - val_loss: 0.2364\n",
      "Epoch 28/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.2319 - val_loss: 0.2341\n",
      "Epoch 29/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.2297 - val_loss: 0.2317\n",
      "Epoch 30/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.2273 - val_loss: 0.2293\n",
      "Epoch 31/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.2249 - val_loss: 0.2270\n",
      "Epoch 32/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.2227 - val_loss: 0.2246\n",
      "Epoch 33/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.2199 - val_loss: 0.2219\n",
      "Epoch 34/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.2171 - val_loss: 0.2193\n",
      "Epoch 35/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.2141 - val_loss: 0.2165\n",
      "Epoch 36/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.2111 - val_loss: 0.2136\n",
      "Epoch 37/400\n",
      "434/434 [==============================] - 0s 54us/sample - loss: 0.2082 - val_loss: 0.2105\n",
      "Epoch 38/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.2047 - val_loss: 0.2073\n",
      "Epoch 39/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.2017 - val_loss: 0.2039\n",
      "Epoch 40/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1986 - val_loss: 0.2007\n",
      "Epoch 41/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1951 - val_loss: 0.1978\n",
      "Epoch 42/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1919 - val_loss: 0.1952\n",
      "Epoch 43/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1884 - val_loss: 0.1919\n",
      "Epoch 44/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1849 - val_loss: 0.1887\n",
      "Epoch 45/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1814 - val_loss: 0.1856\n",
      "Epoch 46/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1783 - val_loss: 0.1825\n",
      "Epoch 47/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1747 - val_loss: 0.1797\n",
      "Epoch 48/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1719 - val_loss: 0.1767\n",
      "Epoch 49/400\n",
      "434/434 [==============================] - 0s 58us/sample - loss: 0.1683 - val_loss: 0.1733\n",
      "Epoch 50/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1654 - val_loss: 0.1706\n",
      "Epoch 51/400\n",
      "434/434 [==============================] - 0s 59us/sample - loss: 0.1625 - val_loss: 0.1686\n",
      "Epoch 52/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1600 - val_loss: 0.1671\n",
      "Epoch 53/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1580 - val_loss: 0.1654\n",
      "Epoch 54/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1566 - val_loss: 0.1639\n",
      "Epoch 55/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1544 - val_loss: 0.1612\n",
      "Epoch 56/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1530 - val_loss: 0.1593\n",
      "Epoch 57/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1516 - val_loss: 0.1575\n",
      "Epoch 58/400\n",
      "434/434 [==============================] - 0s 30us/sample - loss: 0.1501 - val_loss: 0.1569\n",
      "Epoch 59/400\n",
      "434/434 [==============================] - 0s 33us/sample - loss: 0.1489 - val_loss: 0.1563\n",
      "Epoch 60/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1483 - val_loss: 0.1555\n",
      "Epoch 61/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1474 - val_loss: 0.1534\n",
      "Epoch 62/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1469 - val_loss: 0.1523\n",
      "Epoch 63/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1456 - val_loss: 0.1535\n",
      "Epoch 64/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1455 - val_loss: 0.1543\n",
      "Epoch 65/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1452 - val_loss: 0.1530\n",
      "Epoch 66/400\n",
      "434/434 [==============================] - 0s 55us/sample - loss: 0.1442 - val_loss: 0.1506\n",
      "Epoch 67/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1442 - val_loss: 0.1494\n",
      "Epoch 68/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1442 - val_loss: 0.1489\n",
      "Epoch 69/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1432 - val_loss: 0.1498\n",
      "Epoch 70/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1425 - val_loss: 0.1501\n",
      "Epoch 71/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1423 - val_loss: 0.1498\n",
      "Epoch 72/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1419 - val_loss: 0.1495\n",
      "Epoch 73/400\n",
      "434/434 [==============================] - 0s 57us/sample - loss: 0.1412 - val_loss: 0.1487\n",
      "Epoch 74/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1414 - val_loss: 0.1480\n",
      "Epoch 75/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1405 - val_loss: 0.1502\n",
      "Epoch 76/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1410 - val_loss: 0.1495\n",
      "Epoch 77/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1401 - val_loss: 0.1474\n",
      "Epoch 78/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1396 - val_loss: 0.1464\n",
      "Epoch 79/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1398 - val_loss: 0.1461\n",
      "Epoch 80/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1393 - val_loss: 0.1464\n",
      "Epoch 81/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1390 - val_loss: 0.1454\n",
      "Epoch 82/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1390 - val_loss: 0.1472\n",
      "Epoch 83/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1386 - val_loss: 0.1457\n",
      "Epoch 84/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1379 - val_loss: 0.1445\n",
      "Epoch 85/400\n",
      "434/434 [==============================] - 0s 56us/sample - loss: 0.1381 - val_loss: 0.1446\n",
      "Epoch 86/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1375 - val_loss: 0.1453\n",
      "Epoch 87/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1373 - val_loss: 0.1477\n",
      "Epoch 88/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1377 - val_loss: 0.1477\n",
      "Epoch 89/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1369 - val_loss: 0.1455\n",
      "Epoch 90/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1365 - val_loss: 0.1445\n",
      "Epoch 91/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1376 - val_loss: 0.1442\n",
      "Epoch 92/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1370 - val_loss: 0.1445\n",
      "Epoch 93/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1364 - val_loss: 0.1458\n",
      "Epoch 94/400\n",
      "434/434 [==============================] - 0s 30us/sample - loss: 0.1362 - val_loss: 0.1449\n",
      "Epoch 95/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.1359 - val_loss: 0.1432\n",
      "Epoch 96/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1357 - val_loss: 0.1431\n",
      "Epoch 97/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1353 - val_loss: 0.1439\n",
      "Epoch 98/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1350 - val_loss: 0.1452\n",
      "Epoch 99/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1352 - val_loss: 0.1449\n",
      "Epoch 100/400\n",
      "434/434 [==============================] - 0s 49us/sample - loss: 0.1354 - val_loss: 0.1442\n",
      "Epoch 101/400\n",
      "434/434 [==============================] - 0s 65us/sample - loss: 0.1349 - val_loss: 0.1446\n",
      "Epoch 102/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1346 - val_loss: 0.1436\n",
      "Epoch 103/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1354 - val_loss: 0.1427\n",
      "Epoch 104/400\n",
      "434/434 [==============================] - 0s 55us/sample - loss: 0.1348 - val_loss: 0.1438\n",
      "Epoch 105/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1342 - val_loss: 0.1451\n",
      "Epoch 106/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1345 - val_loss: 0.1449\n",
      "Epoch 107/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1342 - val_loss: 0.1436\n",
      "Epoch 108/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1339 - val_loss: 0.1441\n",
      "Epoch 109/400\n",
      "434/434 [==============================] - 0s 49us/sample - loss: 0.1338 - val_loss: 0.1444\n",
      "Epoch 110/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1339 - val_loss: 0.1450\n",
      "Epoch 111/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1337 - val_loss: 0.1438\n",
      "Epoch 112/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1335 - val_loss: 0.1434\n",
      "Epoch 113/400\n",
      "434/434 [==============================] - 0s 59us/sample - loss: 0.1333 - val_loss: 0.1437\n",
      "Epoch 114/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1334 - val_loss: 0.1443\n",
      "Epoch 115/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1330 - val_loss: 0.1445\n",
      "Epoch 116/400\n",
      "434/434 [==============================] - 0s 31us/sample - loss: 0.1332 - val_loss: 0.1440\n",
      "Epoch 117/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1329 - val_loss: 0.1441\n",
      "Epoch 118/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1328 - val_loss: 0.1435\n",
      "Epoch 119/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1326 - val_loss: 0.1444\n",
      "Epoch 120/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1329 - val_loss: 0.1452\n",
      "Epoch 121/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1327 - val_loss: 0.1438\n",
      "Epoch 122/400\n",
      "434/434 [==============================] - 0s 58us/sample - loss: 0.1330 - val_loss: 0.1431\n",
      "Epoch 123/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1322 - val_loss: 0.1447\n",
      "Epoch 124/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1332 - val_loss: 0.1459\n",
      "Epoch 125/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1325 - val_loss: 0.1435\n",
      "Epoch 126/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1317 - val_loss: 0.1435\n",
      "Epoch 127/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1322 - val_loss: 0.1441\n",
      "Epoch 128/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1320 - val_loss: 0.1445\n",
      "Epoch 129/400\n",
      "434/434 [==============================] - 0s 60us/sample - loss: 0.1320 - val_loss: 0.1464\n",
      "Epoch 130/400\n",
      "434/434 [==============================] - 0s 49us/sample - loss: 0.1321 - val_loss: 0.1456\n",
      "Epoch 131/400\n",
      "434/434 [==============================] - 0s 62us/sample - loss: 0.1314 - val_loss: 0.1441\n",
      "Epoch 132/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1314 - val_loss: 0.1435\n",
      "Epoch 133/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1319 - val_loss: 0.1435\n",
      "Epoch 134/400\n",
      "434/434 [==============================] - 0s 55us/sample - loss: 0.1312 - val_loss: 0.1456\n",
      "Epoch 135/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1312 - val_loss: 0.1448\n",
      "Epoch 136/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1311 - val_loss: 0.1444\n",
      "Epoch 137/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1310 - val_loss: 0.1448\n",
      "Epoch 138/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1309 - val_loss: 0.1446\n",
      "Epoch 139/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1308 - val_loss: 0.1441\n",
      "Epoch 140/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1311 - val_loss: 0.1442\n",
      "Epoch 141/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1306 - val_loss: 0.1435\n",
      "Epoch 142/400\n",
      "434/434 [==============================] - 0s 29us/sample - loss: 0.1304 - val_loss: 0.1438\n",
      "Epoch 143/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1304 - val_loss: 0.1446\n",
      "Epoch 144/400\n",
      "434/434 [==============================] - 0s 51us/sample - loss: 0.1302 - val_loss: 0.1450\n",
      "Epoch 145/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1309 - val_loss: 0.1458\n",
      "Epoch 146/400\n",
      "434/434 [==============================] - 0s 63us/sample - loss: 0.1300 - val_loss: 0.1443\n",
      "Epoch 147/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1302 - val_loss: 0.1441\n",
      "Epoch 148/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1304 - val_loss: 0.1442\n",
      "Epoch 149/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1299 - val_loss: 0.1440\n",
      "Epoch 150/400\n",
      "434/434 [==============================] - 0s 60us/sample - loss: 0.1299 - val_loss: 0.1453\n",
      "Epoch 151/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1299 - val_loss: 0.1453\n",
      "Epoch 152/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1297 - val_loss: 0.1444\n",
      "Epoch 153/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1300 - val_loss: 0.1442\n",
      "Epoch 154/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1300 - val_loss: 0.1439\n",
      "Epoch 155/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434/434 [==============================] - 0s 56us/sample - loss: 0.1293 - val_loss: 0.1441\n",
      "Epoch 156/400\n",
      "434/434 [==============================] - 0s 31us/sample - loss: 0.1293 - val_loss: 0.1450\n",
      "Epoch 157/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1298 - val_loss: 0.1452\n",
      "Epoch 158/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1297 - val_loss: 0.1445\n",
      "Epoch 159/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1294 - val_loss: 0.1446\n",
      "Epoch 160/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1293 - val_loss: 0.1446\n",
      "Epoch 161/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1295 - val_loss: 0.1446\n",
      "Epoch 162/400\n",
      "434/434 [==============================] - 0s 72us/sample - loss: 0.1290 - val_loss: 0.1459\n",
      "Epoch 163/400\n",
      "434/434 [==============================] - 0s 55us/sample - loss: 0.1290 - val_loss: 0.1457\n",
      "Epoch 164/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1286 - val_loss: 0.1451\n",
      "Epoch 165/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1287 - val_loss: 0.1450\n",
      "Epoch 166/400\n",
      "434/434 [==============================] - 0s 61us/sample - loss: 0.1295 - val_loss: 0.1451\n",
      "Epoch 167/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1293 - val_loss: 0.1449\n",
      "Epoch 168/400\n",
      "434/434 [==============================] - 0s 59us/sample - loss: 0.1286 - val_loss: 0.1455\n",
      "Epoch 169/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1284 - val_loss: 0.1461\n",
      "Epoch 170/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1288 - val_loss: 0.1457\n",
      "Epoch 171/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1282 - val_loss: 0.1462\n",
      "Epoch 172/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1283 - val_loss: 0.1463\n",
      "Epoch 173/400\n",
      "434/434 [==============================] - 0s 49us/sample - loss: 0.1282 - val_loss: 0.1463\n",
      "Epoch 174/400\n",
      "434/434 [==============================] - 0s 33us/sample - loss: 0.1279 - val_loss: 0.1465\n",
      "Epoch 175/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.1280 - val_loss: 0.1459\n",
      "Epoch 176/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1277 - val_loss: 0.1466\n",
      "Epoch 177/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1280 - val_loss: 0.1469\n",
      "Epoch 178/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1277 - val_loss: 0.1460\n",
      "Epoch 179/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1276 - val_loss: 0.1453\n",
      "Epoch 180/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1278 - val_loss: 0.1453\n",
      "Epoch 181/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1278 - val_loss: 0.1463\n",
      "Epoch 182/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1279 - val_loss: 0.1462\n",
      "Epoch 183/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1276 - val_loss: 0.1452\n",
      "Epoch 184/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1276 - val_loss: 0.1454\n",
      "Epoch 185/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1273 - val_loss: 0.1459\n",
      "Epoch 186/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1277 - val_loss: 0.1470\n",
      "Epoch 187/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1275 - val_loss: 0.1462\n",
      "Epoch 188/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1277 - val_loss: 0.1455\n",
      "Epoch 189/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1274 - val_loss: 0.1463\n",
      "Epoch 190/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1271 - val_loss: 0.1474\n",
      "Epoch 191/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1278 - val_loss: 0.1463\n",
      "Epoch 192/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1277 - val_loss: 0.1448\n",
      "Epoch 193/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1271 - val_loss: 0.1451\n",
      "Epoch 194/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1270 - val_loss: 0.1462\n",
      "Epoch 195/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1271 - val_loss: 0.1457\n",
      "Epoch 196/400\n",
      "434/434 [==============================] - 0s 31us/sample - loss: 0.1270 - val_loss: 0.1453\n",
      "Epoch 197/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1267 - val_loss: 0.1459\n",
      "Epoch 198/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1268 - val_loss: 0.1460\n",
      "Epoch 199/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1267 - val_loss: 0.1452\n",
      "Epoch 200/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1266 - val_loss: 0.1453\n",
      "Epoch 201/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1265 - val_loss: 0.1454\n",
      "Epoch 202/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1266 - val_loss: 0.1455\n",
      "Epoch 203/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1269 - val_loss: 0.1454\n",
      "Epoch 204/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1268 - val_loss: 0.1454\n",
      "Epoch 205/400\n",
      "434/434 [==============================] - 0s 69us/sample - loss: 0.1263 - val_loss: 0.1459\n",
      "Epoch 206/400\n",
      "434/434 [==============================] - 0s 66us/sample - loss: 0.1267 - val_loss: 0.1467\n",
      "Epoch 207/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1266 - val_loss: 0.1458\n",
      "Epoch 208/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1264 - val_loss: 0.1458\n",
      "Epoch 209/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1264 - val_loss: 0.1454\n",
      "Epoch 210/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1263 - val_loss: 0.1451\n",
      "Epoch 211/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1262 - val_loss: 0.1448\n",
      "Epoch 212/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1260 - val_loss: 0.1448\n",
      "Epoch 213/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1260 - val_loss: 0.1454\n",
      "Epoch 214/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1258 - val_loss: 0.1463\n",
      "Epoch 215/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1259 - val_loss: 0.1466\n",
      "Epoch 216/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1260 - val_loss: 0.1466\n",
      "Epoch 217/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1262 - val_loss: 0.1466\n",
      "Epoch 218/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1264 - val_loss: 0.1468\n",
      "Epoch 219/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1257 - val_loss: 0.1451\n",
      "Epoch 220/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1261 - val_loss: 0.1452\n",
      "Epoch 221/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1257 - val_loss: 0.1455\n",
      "Epoch 222/400\n",
      "434/434 [==============================] - 0s 51us/sample - loss: 0.1258 - val_loss: 0.1468\n",
      "Epoch 223/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1256 - val_loss: 0.1458\n",
      "Epoch 224/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1253 - val_loss: 0.1453\n",
      "Epoch 225/400\n",
      "434/434 [==============================] - 0s 63us/sample - loss: 0.1259 - val_loss: 0.1453\n",
      "Epoch 226/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1255 - val_loss: 0.1457\n",
      "Epoch 227/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1253 - val_loss: 0.1462\n",
      "Epoch 228/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1254 - val_loss: 0.1462\n",
      "Epoch 229/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.1252 - val_loss: 0.1457\n",
      "Epoch 230/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1250 - val_loss: 0.1454\n",
      "Epoch 231/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1255 - val_loss: 0.1452\n",
      "Epoch 232/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1255 - val_loss: 0.1454\n",
      "Epoch 233/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1251 - val_loss: 0.1462\n",
      "Epoch 234/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.1253 - val_loss: 0.1464\n",
      "Epoch 235/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1249 - val_loss: 0.1461\n",
      "Epoch 236/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1249 - val_loss: 0.1460\n",
      "Epoch 237/400\n",
      "434/434 [==============================] - 0s 54us/sample - loss: 0.1249 - val_loss: 0.1459\n",
      "Epoch 238/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1247 - val_loss: 0.1464\n",
      "Epoch 239/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1251 - val_loss: 0.1475\n",
      "Epoch 240/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1253 - val_loss: 0.1459\n",
      "Epoch 241/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1248 - val_loss: 0.1457\n",
      "Epoch 242/400\n",
      "434/434 [==============================] - 0s 49us/sample - loss: 0.1253 - val_loss: 0.1456\n",
      "Epoch 243/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1255 - val_loss: 0.1477\n",
      "Epoch 244/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1249 - val_loss: 0.1463\n",
      "Epoch 245/400\n",
      "434/434 [==============================] - 0s 51us/sample - loss: 0.1246 - val_loss: 0.1461\n",
      "Epoch 246/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1248 - val_loss: 0.1458\n",
      "Epoch 247/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1246 - val_loss: 0.1464\n",
      "Epoch 248/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1243 - val_loss: 0.1460\n",
      "Epoch 249/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1245 - val_loss: 0.1465\n",
      "Epoch 250/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1250 - val_loss: 0.1466\n",
      "Epoch 251/400\n",
      "434/434 [==============================] - 0s 51us/sample - loss: 0.1248 - val_loss: 0.1471\n",
      "Epoch 252/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1241 - val_loss: 0.1467\n",
      "Epoch 253/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1241 - val_loss: 0.1464\n",
      "Epoch 254/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1243 - val_loss: 0.1466\n",
      "Epoch 255/400\n",
      "434/434 [==============================] - 0s 61us/sample - loss: 0.1243 - val_loss: 0.1482\n",
      "Epoch 256/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1248 - val_loss: 0.1477\n",
      "Epoch 257/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1236 - val_loss: 0.1467\n",
      "Epoch 258/400\n",
      "434/434 [==============================] - 0s 55us/sample - loss: 0.1241 - val_loss: 0.1468\n",
      "Epoch 259/400\n",
      "434/434 [==============================] - 0s 60us/sample - loss: 0.1239 - val_loss: 0.1471\n",
      "Epoch 260/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1240 - val_loss: 0.1485\n",
      "Epoch 261/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1241 - val_loss: 0.1470\n",
      "Epoch 262/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1241 - val_loss: 0.1464\n",
      "Epoch 263/400\n",
      "434/434 [==============================] - 0s 62us/sample - loss: 0.1242 - val_loss: 0.1463\n",
      "Epoch 264/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1237 - val_loss: 0.1477\n",
      "Epoch 265/400\n",
      "434/434 [==============================] - 0s 33us/sample - loss: 0.1238 - val_loss: 0.1476\n",
      "Epoch 266/400\n",
      "434/434 [==============================] - 0s 51us/sample - loss: 0.1234 - val_loss: 0.1475\n",
      "Epoch 267/400\n",
      "434/434 [==============================] - 0s 52us/sample - loss: 0.1235 - val_loss: 0.1477\n",
      "Epoch 268/400\n",
      "434/434 [==============================] - 0s 56us/sample - loss: 0.1235 - val_loss: 0.1478\n",
      "Epoch 269/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1234 - val_loss: 0.1470\n",
      "Epoch 270/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1232 - val_loss: 0.1465\n",
      "Epoch 271/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1231 - val_loss: 0.1471\n",
      "Epoch 272/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1246 - val_loss: 0.1472\n",
      "Epoch 273/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1232 - val_loss: 0.1462\n",
      "Epoch 274/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1243 - val_loss: 0.1463\n",
      "Epoch 275/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1232 - val_loss: 0.1468\n",
      "Epoch 276/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1232 - val_loss: 0.1480\n",
      "Epoch 277/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1232 - val_loss: 0.1471\n",
      "Epoch 278/400\n",
      "434/434 [==============================] - 0s 63us/sample - loss: 0.1224 - val_loss: 0.1469\n",
      "Epoch 279/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1234 - val_loss: 0.1472\n",
      "Epoch 280/400\n",
      "434/434 [==============================] - 0s 63us/sample - loss: 0.1231 - val_loss: 0.1478\n",
      "Epoch 281/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1229 - val_loss: 0.1481\n",
      "Epoch 282/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1226 - val_loss: 0.1474\n",
      "Epoch 283/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1223 - val_loss: 0.1475\n",
      "Epoch 284/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1226 - val_loss: 0.1479\n",
      "Epoch 285/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1228 - val_loss: 0.1476\n",
      "Epoch 286/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1223 - val_loss: 0.1474\n",
      "Epoch 287/400\n",
      "434/434 [==============================] - 0s 57us/sample - loss: 0.1231 - val_loss: 0.1479\n",
      "Epoch 288/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1223 - val_loss: 0.1487\n",
      "Epoch 289/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1229 - val_loss: 0.1493\n",
      "Epoch 290/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1224 - val_loss: 0.1475\n",
      "Epoch 291/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1234 - val_loss: 0.1476\n",
      "Epoch 292/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1235 - val_loss: 0.1469\n",
      "Epoch 293/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1221 - val_loss: 0.1496\n",
      "Epoch 294/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1241 - val_loss: 0.1496\n",
      "Epoch 295/400\n",
      "434/434 [==============================] - 0s 61us/sample - loss: 0.1231 - val_loss: 0.1480\n",
      "Epoch 296/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1235 - val_loss: 0.1477\n",
      "Epoch 297/400\n",
      "434/434 [==============================] - 0s 56us/sample - loss: 0.1221 - val_loss: 0.1479\n",
      "Epoch 298/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1223 - val_loss: 0.1487\n",
      "Epoch 299/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1224 - val_loss: 0.1480\n",
      "Epoch 300/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1221 - val_loss: 0.1485\n",
      "Epoch 301/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1221 - val_loss: 0.1484\n",
      "Epoch 302/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1218 - val_loss: 0.1492\n",
      "Epoch 303/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1223 - val_loss: 0.1486\n",
      "Epoch 304/400\n",
      "434/434 [==============================] - 0s 51us/sample - loss: 0.1218 - val_loss: 0.1475\n",
      "Epoch 305/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1227 - val_loss: 0.1472\n",
      "Epoch 306/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1213 - val_loss: 0.1489\n",
      "Epoch 307/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1223 - val_loss: 0.1494\n",
      "Epoch 308/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1216 - val_loss: 0.1482\n",
      "Epoch 309/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1230 - val_loss: 0.1485\n",
      "Epoch 310/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1213 - val_loss: 0.1494\n",
      "Epoch 311/400\n",
      "434/434 [==============================] - 0s 55us/sample - loss: 0.1222 - val_loss: 0.1498\n",
      "Epoch 312/400\n",
      "434/434 [==============================] - 0s 45us/sample - loss: 0.1218 - val_loss: 0.1479\n",
      "Epoch 313/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1215 - val_loss: 0.1480\n",
      "Epoch 314/400\n",
      "434/434 [==============================] - 0s 30us/sample - loss: 0.1218 - val_loss: 0.1482\n",
      "Epoch 315/400\n",
      "434/434 [==============================] - 0s 31us/sample - loss: 0.1211 - val_loss: 0.1485\n",
      "Epoch 316/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1210 - val_loss: 0.1487\n",
      "Epoch 317/400\n",
      "434/434 [==============================] - 0s 49us/sample - loss: 0.1210 - val_loss: 0.1491\n",
      "Epoch 318/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1209 - val_loss: 0.1498\n",
      "Epoch 319/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1212 - val_loss: 0.1499\n",
      "Epoch 320/400\n",
      "434/434 [==============================] - 0s 31us/sample - loss: 0.1210 - val_loss: 0.1489\n",
      "Epoch 321/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1209 - val_loss: 0.1488\n",
      "Epoch 322/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1207 - val_loss: 0.1494\n",
      "Epoch 323/400\n",
      "434/434 [==============================] - 0s 65us/sample - loss: 0.1212 - val_loss: 0.1499\n",
      "Epoch 324/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1212 - val_loss: 0.1493\n",
      "Epoch 325/400\n",
      "434/434 [==============================] - 0s 31us/sample - loss: 0.1208 - val_loss: 0.1494\n",
      "Epoch 326/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1208 - val_loss: 0.1497\n",
      "Epoch 327/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1207 - val_loss: 0.1493\n",
      "Epoch 328/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1206 - val_loss: 0.1495\n",
      "Epoch 329/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1204 - val_loss: 0.1499\n",
      "Epoch 330/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1207 - val_loss: 0.1504\n",
      "Epoch 331/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1207 - val_loss: 0.1494\n",
      "Epoch 332/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.1220 - val_loss: 0.1496\n",
      "Epoch 333/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1215 - val_loss: 0.1494\n",
      "Epoch 334/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1215 - val_loss: 0.1508\n",
      "Epoch 335/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1207 - val_loss: 0.1498\n",
      "Epoch 336/400\n",
      "434/434 [==============================] - 0s 33us/sample - loss: 0.1205 - val_loss: 0.1496\n",
      "Epoch 337/400\n",
      "434/434 [==============================] - 0s 32us/sample - loss: 0.1205 - val_loss: 0.1495\n",
      "Epoch 338/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1203 - val_loss: 0.1497\n",
      "Epoch 339/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1202 - val_loss: 0.1497\n",
      "Epoch 340/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1209 - val_loss: 0.1502\n",
      "Epoch 341/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1205 - val_loss: 0.1500\n",
      "Epoch 342/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1202 - val_loss: 0.1500\n",
      "Epoch 343/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1204 - val_loss: 0.1501\n",
      "Epoch 344/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1202 - val_loss: 0.1499\n",
      "Epoch 345/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1200 - val_loss: 0.1502\n",
      "Epoch 346/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1206 - val_loss: 0.1509\n",
      "Epoch 347/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1198 - val_loss: 0.1506\n",
      "Epoch 348/400\n",
      "434/434 [==============================] - 0s 33us/sample - loss: 0.1202 - val_loss: 0.1511\n",
      "Epoch 349/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1203 - val_loss: 0.1507\n",
      "Epoch 350/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1200 - val_loss: 0.1510\n",
      "Epoch 351/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1201 - val_loss: 0.1505\n",
      "Epoch 352/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1202 - val_loss: 0.1494\n",
      "Epoch 353/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1196 - val_loss: 0.1492\n",
      "Epoch 354/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1196 - val_loss: 0.1491\n",
      "Epoch 355/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1198 - val_loss: 0.1490\n",
      "Epoch 356/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1194 - val_loss: 0.1497\n",
      "Epoch 357/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1195 - val_loss: 0.1499\n",
      "Epoch 358/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1193 - val_loss: 0.1499\n",
      "Epoch 359/400\n",
      "434/434 [==============================] - 0s 44us/sample - loss: 0.1192 - val_loss: 0.1496\n",
      "Epoch 360/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1193 - val_loss: 0.1496\n",
      "Epoch 361/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1194 - val_loss: 0.1499\n",
      "Epoch 362/400\n",
      "434/434 [==============================] - 0s 42us/sample - loss: 0.1194 - val_loss: 0.1492\n",
      "Epoch 363/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1193 - val_loss: 0.1492\n",
      "Epoch 364/400\n",
      "434/434 [==============================] - 0s 53us/sample - loss: 0.1190 - val_loss: 0.1495\n",
      "Epoch 365/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1190 - val_loss: 0.1499\n",
      "Epoch 366/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1189 - val_loss: 0.1497\n",
      "Epoch 367/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1190 - val_loss: 0.1497\n",
      "Epoch 368/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1191 - val_loss: 0.1499\n",
      "Epoch 369/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1188 - val_loss: 0.1503\n",
      "Epoch 370/400\n",
      "434/434 [==============================] - 0s 48us/sample - loss: 0.1190 - val_loss: 0.1502\n",
      "Epoch 371/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1187 - val_loss: 0.1504\n",
      "Epoch 372/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1189 - val_loss: 0.1505\n",
      "Epoch 373/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1189 - val_loss: 0.1508\n",
      "Epoch 374/400\n",
      "434/434 [==============================] - 0s 50us/sample - loss: 0.1188 - val_loss: 0.1504\n",
      "Epoch 375/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1186 - val_loss: 0.1508\n",
      "Epoch 376/400\n",
      "434/434 [==============================] - 0s 51us/sample - loss: 0.1185 - val_loss: 0.1508\n",
      "Epoch 377/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1184 - val_loss: 0.1506\n",
      "Epoch 378/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1188 - val_loss: 0.1505\n",
      "Epoch 379/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1186 - val_loss: 0.1502\n",
      "Epoch 380/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1184 - val_loss: 0.1505\n",
      "Epoch 381/400\n",
      "434/434 [==============================] - 0s 39us/sample - loss: 0.1182 - val_loss: 0.1509\n",
      "Epoch 382/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1183 - val_loss: 0.1511\n",
      "Epoch 383/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1182 - val_loss: 0.1510\n",
      "Epoch 384/400\n",
      "434/434 [==============================] - 0s 47us/sample - loss: 0.1197 - val_loss: 0.1509\n",
      "Epoch 385/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1182 - val_loss: 0.1515\n",
      "Epoch 386/400\n",
      "434/434 [==============================] - 0s 38us/sample - loss: 0.1191 - val_loss: 0.1511\n",
      "Epoch 387/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1180 - val_loss: 0.1506\n",
      "Epoch 388/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1186 - val_loss: 0.1506\n",
      "Epoch 389/400\n",
      "434/434 [==============================] - 0s 37us/sample - loss: 0.1181 - val_loss: 0.1504\n",
      "Epoch 390/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1181 - val_loss: 0.1507\n",
      "Epoch 391/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1182 - val_loss: 0.1511\n",
      "Epoch 392/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1179 - val_loss: 0.1511\n",
      "Epoch 393/400\n",
      "434/434 [==============================] - 0s 41us/sample - loss: 0.1182 - val_loss: 0.1508\n",
      "Epoch 394/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1177 - val_loss: 0.1512\n",
      "Epoch 395/400\n",
      "434/434 [==============================] - 0s 34us/sample - loss: 0.1181 - val_loss: 0.1505\n",
      "Epoch 396/400\n",
      "434/434 [==============================] - 0s 36us/sample - loss: 0.1181 - val_loss: 0.1504\n",
      "Epoch 397/400\n",
      "434/434 [==============================] - 0s 40us/sample - loss: 0.1185 - val_loss: 0.1507\n",
      "Epoch 398/400\n",
      "434/434 [==============================] - 0s 43us/sample - loss: 0.1175 - val_loss: 0.1514\n",
      "Epoch 399/400\n",
      "434/434 [==============================] - 0s 46us/sample - loss: 0.1177 - val_loss: 0.1517\n",
      "Epoch 400/400\n",
      "434/434 [==============================] - 0s 35us/sample - loss: 0.1178 - val_loss: 0.1512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04bc55d160>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation data pode mostrar se estamos tendo problemas de overfit, plota o train e test\n",
    "# batch_size = quanto menor menos chance de overfit(64,128,256...)\n",
    "\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test),\n",
    "                                                batch_size=128, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f04b46fadd8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29634609089337566\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.605049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.151067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.681893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.333352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.189935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.599146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.000196\n",
       "1    0.605049\n",
       "2    0.151067\n",
       "3    0.166361\n",
       "4    0.177636\n",
       "..        ...\n",
       "182  0.681893\n",
       "183  0.333352\n",
       "184  0.189935\n",
       "185  0.292700\n",
       "186  0.599146\n",
       "\n",
       "[187 rows x 1 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>0.00500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0.14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>756</td>\n",
       "      <td>0.88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>660</td>\n",
       "      <td>0.79000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>799</td>\n",
       "      <td>0.48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>197</td>\n",
       "      <td>0.15507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>762</td>\n",
       "      <td>0.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>99</td>\n",
       "      <td>0.78050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>185</td>\n",
       "      <td>0.62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>4</td>\n",
       "      <td>0.87000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            132   0.00500\n",
       "1             39   0.14000\n",
       "2            756   0.88000\n",
       "3            660   0.79000\n",
       "4            799   0.48000\n",
       "..           ...       ...\n",
       "263          197   0.15507\n",
       "264          762   0.01000\n",
       "265           99   0.78050\n",
       "266          185   0.62000\n",
       "267            4   0.87000\n",
       "\n",
       "[268 rows x 2 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/exemplo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male',\n",
       "       'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare','Sex','Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Sex         0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['Age'] = test['Age'].fillna(test['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>113.2750</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>3</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>3</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass    Age  SibSp  Parch      Fare     Sex Embarked\n",
       "0         3  20.00      0      0    7.0500    male        S\n",
       "1         3  18.00      2      0   18.0000  female        S\n",
       "2         2   0.67      1      1   14.5000    male        S\n",
       "3         1  58.00      0      2  113.2750    male        C\n",
       "4         3  30.00      0      0    7.2292    male        C\n",
       "..      ...    ...    ...    ...       ...     ...      ...\n",
       "263       3  28.00      0      0    7.7500    male        Q\n",
       "264       3  41.00      0      0    7.1250    male        S\n",
       "265       2  34.00      0      1   23.0000  female        S\n",
       "266       3   4.00      0      2   22.0250  female        S\n",
       "267       1  35.00      1      0   53.1000  female        S\n",
       "\n",
       "[268 rows x 7 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Embarked']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dummies_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>113.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass    Age  SibSp  Parch      Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "0       3  20.00      0      0    7.0500         1           0           1\n",
       "1       3  18.00      2      0   18.0000         0           0           1\n",
       "2       2   0.67      1      1   14.5000         1           0           1\n",
       "3       1  58.00      0      2  113.2750         1           0           0\n",
       "4       3  30.00      0      0    7.2292         1           0           0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(test[list_dummies_object], drop_first=True)\n",
    "test_dummy = pd.concat([test.drop(list_dummies_object, axis=1), dummies], axis=1)\n",
    "test_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummy = test_dummy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scaler.transform(test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.246, 0.   , ..., 1.   , 0.   , 1.   ],\n",
       "       [1.   , 0.221, 0.25 , ..., 0.   , 0.   , 1.   ],\n",
       "       [0.5  , 0.003, 0.125, ..., 1.   , 0.   , 1.   ],\n",
       "       ...,\n",
       "       [0.5  , 0.422, 0.   , ..., 0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.045, 0.   , ..., 0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.435, 0.125, ..., 0.   , 0.   , 1.   ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.057941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.158813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.970044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.376651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.994302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.156044\n",
       "1    0.548956\n",
       "2    0.509381\n",
       "3    0.221025\n",
       "4    0.150299\n",
       "..        ...\n",
       "263  0.057941\n",
       "264  0.158813\n",
       "265  0.970044\n",
       "266  0.376651\n",
       "267  0.994302\n",
       "\n",
       "[268 rows x 1 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerId = pd.read_csv('data/test.csv')['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerId['Survived'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>0.156044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0.548956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>756</td>\n",
       "      <td>0.509381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>660</td>\n",
       "      <td>0.221025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>799</td>\n",
       "      <td>0.150299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          132  0.156044\n",
       "1           39  0.548956\n",
       "2          756  0.509381\n",
       "3          660  0.221025\n",
       "4          799  0.150299"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(PassengerId)\n",
    "result['Survived'] = pred\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[['Survived']] = result[['Survived']].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived]\n",
       "Index: []"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['Survived']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for n in range (len(result['Survived'])):\n",
    "    if result['Survived'][n] > 1:\n",
    "        result['Survived'][n] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/home/lucas/PycharmProjects/git/Kaggle competitions/result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>431.186567</td>\n",
       "      <td>0.330233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>270.945388</td>\n",
       "      <td>0.306744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.250000</td>\n",
       "      <td>0.109986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.173681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>677.000000</td>\n",
       "      <td>0.530637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>887.000000</td>\n",
       "      <td>0.998307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived\n",
       "count   268.000000  268.000000\n",
       "mean    431.186567    0.330233\n",
       "std     270.945388    0.306744\n",
       "min       4.000000    0.000000\n",
       "25%     177.250000    0.109986\n",
       "50%     439.000000    0.173681\n",
       "75%     677.000000    0.530637\n",
       "max     887.000000    0.998307"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 2)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
